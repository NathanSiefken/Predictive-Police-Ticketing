---
title: "Test PDF"
author: "Nathan Siefken"
date: "2/3/2019"
output:
  html_document:
    df_print: paged
---

```{r, warning=FALSE}
# This code chunk simply makes sure that all the libraries used here are installed. 
packages <- c("knitr","dplyr",  "tidyr", "caret", "ggplot2", "caret", "plotly","lubridate","leaflet", "stringr","rpart.plot", "rpart")
if ( length(missing_pkgs <- setdiff(packages, rownames(installed.packages()))) > 0) {
message("Installing missing package(s): ", paste(missing_pkgs, collapse = ", "))
install.packages(missing_pkgs)
}

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading libraries
library(tidyr) 
library(dplyr)
library(ggplot2)
library(lubridate) # for working with dates
library(plotly) # for interactive plots
library(janitor)
library(leaflet) # Geomapping
library(colorRamps)
library(proj4)
library(validate)
library(stringr)
library(rpart)
library(rpart.plot)
library(caret)
FTP<- read.csv("FTP.csv", stringsAsFactors = FALSE)
```

## Intro: 


## Cleaning our Data

We will combine the Issue.Date and the Issue.Time into it's own column. To do this we will need to restucture the data
into a time series friendly format.

Now there is time stamp on all the dates, "T00:00:00", that needs to be removed.
```{r}
#Removing excess information
FTP$Issue.Date <- sub("T.*", "", FTP$Issue.Date)
```

We will use some string processing techniqes to clean up our Issue.Time column

```{r pressure, echo=FALSE}
#Now to put our time into a format that we can use
FTP$Issue.time<-sub("(\\d*)(\\d{2})", "\\1:\\2", FTP$Issue.time) # put in delimitter
# The single digit strings were missed, so this code will convert them
FTP$Issue.time <- str_replace(FTP$Issue.time, "^([0-9])$",":0\\1")
# Now we will need to pad our times with a 0 before the ":" for all data that was less than 1:00
FTP$Issue.time <- sprintf("%04s", FTP$Issue.time)
```
Let's take a look at the data and see if there is anything else we can wrangle

We can see in Latitude and Longitude a default value of 99999 that will need to be removed. 

```{r}
##We can notice that there is a default of 99999 when a cordinate isn't entered. We will remove these
FTP<- FTP %>%
  filter(Latitude != 99999) 
```

Now for converting the cordinates from US feet to Logitutde and Latitude cordinates

```{r}
#Create projection element to convert from US Feet coordinates to normal lat lon
pj <- "+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 +y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 no_defs"

#Add converted latitude longitude to FTP dataframe
FTP<- cbind(FTP, data.frame(project(data.frame(FTP$Latitude, FTP$Longitude), proj = pj, inverse = TRUE)))
str(FTP)
FTP <- FTP[-9:-10] #This removes the Latitude and Logitude in Feet from our table
names(FTP)[c(9, 10)] <- c('Longitude', 'Latitude') #Rename column names of converted longitude latitude
# Now our data is looking clean and usable
summary(FTP)
```

After all the cleaning of our data, now we can format date and time, so we can better work with it in R

```{r}
FTP$Date <- as.POSIXlt(paste(FTP$Issue.Date, FTP$Issue.time), format="%Y-%m-%d %H:%M")
```
Now lets identify the weekday each ticket was given and put it into a column
```{r}
FTP$Weekdays <- weekdays(FTP$Date)
```
We can also store the hour of the day that the tickets were given and add a column
```{r}
FTP$Hour <- FTP$Date$hour
summary(FTP)
```


```{r}
sum(is.na(FTP)) #check for how many NAs there are
FTP <- na.omit(FTP)# Very few for this many observation (less than 1%)
FTP <- FTP[-11]
summary(FTP)
```
:Analysing the data
First lets see the revenue they generated in a year
```{r}
revenue <- sum(FTP$Fine.amount)
revenue
```

Filter top 10 Violations
```{r}
TopViolations <- FTP %>% 
  group_by(Violation.Description) %>% 
  tally() %>% 
  arrange(-n) %>% 
  head(10)

TopViolations
```

Now lets graph top 10 Violations throughout the year

```{r}

#I need to make this for month and not year
TopViolationsLastYears <- FTP %>% 
  filter(Violation.Description %in%
           TopViolations$Violation.Description)


p <- ggplot(TopViolationsLastYears, aes(Issue.Date)) + 
  geom_bar(aes(fill=Violation.Description), stat='count')
#Plot the data), stat='count')
ggplotly(p)


```
