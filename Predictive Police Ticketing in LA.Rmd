---
title: "Predictive Police Ticketing: Using Machine Learning to Detect Patterns"
author: "Nathan Siefken"
date: "2/3/2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Motivation 

Imagine that you are in downtown Los Angeles and you are the waiting for your name to be called at the building department on a Wednesday. Your business project is on hold pending these building permits. It is 12 noon and your number is about to be called, but this took longer than you expected, and your parking meter is about to run out. What do you do? Or maybe you need to run into the Santa Monica grocery store to buy milk for your baby at 8am on a Saturday. You find a parking spot just in front, but it's turns out to be a red curb. The cry of your baby is pulling at the threads of your maternal/paternal instincts. Is it worth a ticket? Are you likely to get a ticket?

I am not encouraging you to break the law. In fact, you have 0 chance (assuming no human police error) of getting a ticket if you follow the rules. However, We will learn that there are about 130,000 tickets issued just this past month and it is likely that some of these people were weighing their options prior to receiving a ticket. Life is full of circumstances, and a person may want to have more information to help aid them in the decisions. 

## Process for our Prediction Project: 

* __Know our Goal:__ In this case we want to predict how many parking tickets are being issued at any hour of the day, on any day of the week.

<p>

*	__Data Wrangling:__ Structuring data to create more useful output.

<p>

*	__Implementing Exploratory Analysis:__ Determine if there are any sort of patterns in our data before going into building the models. 

<p>

*	__Creating and Test Baseline Model:__  This model is our point of reference. The RMSE of our other models should be better (lower) than this model to prove they are learning.

<p>

*	__Create and Test Linear Regression Model:__ Determine if the dependent variable interacts with the independent variables in a linear fashion. How well does this model predict?

<p>

*	__Create and Test Regression Tree Model:__ This model uses recursive partitioning to separate data in to smaller regions that are similar. Discover if the data interacts in complicated nonlinear ways. Is this our best prediction model?

<p>

*	__Cross Validation:__ Decide if our best model suffers from overfitting and change the cp accordingly.

<p>

*	__Conclusion:__ Compare the results of our models and conclude the usefulness of our best algorithm

## Measuring our models:

I use Root Mean Squared Error or RMSE to measure the predictions of my models. If you are familiar with Kaggle, the online community of data scientists and machine learners, they too, use RMSE or MAE as the metric for judging their competitions.

## Data Set

This data set is maintained and regularly updated by Kaggle which is acquired from the city of Los Angeles organization page.

Kaggle Data Set: https://www.kaggle.com/cityofLA/los-angeles-parking-citations/home


## Data Wrangling:

I started by sub-setting the dates of our data from December 23, 2018 to January 23, 2019. Then, I restructured the values in the date and time columns into a time series friendly format to easily separate out the days of the week and the hours of the day for each observation; then place them into their own column. I then converted the US feet coordinates into the universal Longitude and Latitude coordinates. We take care of our Null values and the following is the structure of our cleaned data set.


```{r, warning=FALSE, echo=FALSE}
# This code chunk simply makes sure that all the libraries used here are installed. 
packages <- c("knitr","dplyr",  "tidyr", "caret", "ggplot2", "caret",
              "plotly","lubridate","leaflet", "stringr","rpart.plot", "rpart")
if ( length(missing_pkgs <- setdiff(packages, rownames(installed.packages()))) > 0) {
message("Installing missing package(s): ", paste(missing_pkgs, collapse = ", "))
install.packages(missing_pkgs)
}

```
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading libraries
library(tidyr) 
library(dplyr)
library(ggplot2)
library(lubridate) # for working with dates
library(plotly) # for interactive plots
library(janitor)
library(leaflet) # Geomapping
library(colorRamps)
library(proj4)
library(validate)
library(stringr)
library(rpart)
library(rpart.plot)
library(caret)
library(knitr)
FTP<- read.csv("FTP.csv", stringsAsFactors = FALSE)
```
```{r, echo=FALSE}
#Removing excess information with string processing
FTP$Issue.Date <- sub("T.*", "", FTP$Issue.Date)
#Now to put our time into a format that we can use
FTP$Issue.time<-sub("(\\d*)(\\d{2})", "\\1:\\2", FTP$Issue.time) # put in delimitter
# The single digit strings were missed, so this code will convert them
FTP$Issue.time <- str_replace(FTP$Issue.time, "^([0-9])$",":0\\1")
# Now we will need to pad our times with a 0 before the ":" for all data that was less than 1:00
FTP$Issue.time <- sprintf("%04s", FTP$Issue.time)

#We can notice that there is a default of 99999 when a coordinate isn't entered.
#We will remove these
FTP<- FTP %>%
  filter(Latitude != 99999) 
#Create projection element to convert from US Feet coordinates to normal lat lon
proj <- "+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 +y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 no_defs"
#Add converted latitude longitude to FTP data frame
FTP<- cbind(FTP, data.frame(project(data.frame(FTP$Latitude, FTP$Longitude), proj = proj,
                                    inverse = TRUE)))
FTP <- FTP[-9:-10] #This removes the Latitude and Longitude  in Feet from our table
names(FTP)[c(9, 10)] <- c('Longitude', 'Latitude') #Rename column names of converted 

```

```{r, echo=FALSE}
#combined the date and time
FTP$Date <- as.POSIXlt(paste(FTP$Issue.Date, FTP$Issue.time), format="%Y-%m-%d %H:%M")
#Seperate the days of the week tickets where given and place it into a column
FTP$Weekdays <- weekdays(FTP$Date)
#Seperate the Hours of the day tickets where given and place it into a column
FTP$Hour <- FTP$Date$hour

FTP <- na.omit(FTP)# Very few for this many observation (less than 1%)
FTP <- FTP[-11] #We will remove our date column because we are
# not able to preform some calculations when a column is in POSIXlt format.
str(FTP)
```


##Exploratory Data Analysis:

The goal of our exploratory data analysis or EDA is to find patterns in our data and the variables that are significant in these patterns. Once we understand our data and correctly identified the variables that we will use in our machine learning algorithms we will be able to start the modeling process. A good EDA can be used to support the results of machine learning models.


To start, we learned from the structure of our data above, there are a 130,298 observations which are the number of tickets issued. Below I calculated the revenue these tickets generated.
<p>
```{r, echo=FALSE}
#Good
revenue <- FTP %>% summarize(Revenue = sum(Fine.amount))
revenue %>% knitr::kable()
```

That is $9,221,737 of guaranteed revenue. This is of course assuming that the tickets are paid in full and on time. Otherwise additional fees or penalties may be garnered. 

\pagebreak

__Bar Chart Of Top 5 Violations Issued__

And here we see a bar chart that visualizes the distribution of violations that account for the majority of the tickets issued on each day from December 23, 2018 to January 23, 2019.

```{r ,fig.align='center',out.width="400px", out.height="350px", echo=FALSE}
TopViolations <- FTP %>% 
  group_by(Violation.Description) %>% 
  tally() %>% 
  arrange(-n) %>% 
  head(5)

TopViolationsLastYears <- FTP %>% 
  filter(Violation.Description %in%
           TopViolations$Violation.Description)

barTop5 <- ggplot(TopViolationsLastYears, aes(Issue.Date)) + 
  geom_bar(aes(fill=Violation.Description), stat='count')+
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +ggtitle("Top Five Violations")
#Plot the data), stat='count')
barTop5
```

__Line Plot For Total Tickets Issued__

This line chart is the perfect visualization to show the total number of tickets issued for each day of the week. We can easily see the days have high volumes of tickets issued and days which have lower amounts of tickets issued.

```{r ,fig.align='center',out.width="350px", out.height="300px", echo=FALSE}

WeekdayCounts = as.data.frame(table(FTP$Weekday))

WeekdayCounts$Var1 = factor(WeekdayCounts$Var1, ordered=TRUE,
                            levels=c("Sunday","Monday", "Tuesday","Wednesday",
                                     "Thursday", "Friday","Saturday")) 
#We can change the Var1 variable to be an ordered factor variable
ggplot(WeekdayCounts, aes(x=Var1, y=Freq, color = "blue")) + geom_line(aes(group=1), size = 1) +
  xlab("Day of the Week") + ylab("Ticket Issued")+ scale_colour_manual(values="#339999")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))+ ggtitle("Tickets Issued by Day of the Week") + theme(legend.position="none")

```

__Line Plot For Day Of The Week And Hour Of The Day__

To expand on the previous line graph, I included the hours of the day. To do this I charted on the graph to the left, each day of the week by color and the frequency of the tickets issued each hour. Now we can easily see the number of tickets being issued each hour of each day.

Then on the graph to the right, I charted the weekdays and the weekend by color and the frequency of the tickets issued. This gives a nice comparison between the number of tickets issued on weekdays versus weekends.



```{r,echo=FALSE, out.width='.49\\linewidth', fig.width=5.5, fig.height=4,fig.show='hold',fig.align='center'}
# This will create our table
#
#We will save this as a data frame 
DayHourCounts = as.data.frame(table(FTP$Weekday, FTP$Hour))
# Convert the second variable, Var2, to numbers and call it Hour:
DayHourCounts$Hour = as.numeric(as.character(DayHourCounts$Var2))
# Create out plot:

# Fix the order of the days and add color
ggplot(DayHourCounts, aes(x=Hour, y=Freq)) + geom_line(aes(group=Var1,
                                                           color=Var1), size=2,alpha=0.7)+ggtitle("Tickets Issued by Hour and Day of the Week")
  

DayHourCounts$Type = ifelse((DayHourCounts$Var1 == "Sunday") |
                              (DayHourCounts$Var1 == "Saturday"),
                            "Weekend", "Weekday")
# Redo our plot, this time coloring by Type:

ggplot(DayHourCounts, aes(x=Hour, y=Freq)) + 
  geom_line(aes(group=Var1,color=Type), size=2,alpha=0.5) +ggtitle("Tickets Issued by Hour and Weekday or Weekend")

```

__Heat Map For Another Interpretation__

Let's now plot a heatmap to visualize  the data in a different manner. The heatmap is sorted by days of the week and hours of the day. The frequency of tickets issued goes from white (low) to red (high) to give a good understanding of the frequency of our data. 
```{r ,fig.align='center',out.width="350px", out.height="300px", echo=FALSE}
# Fix the order of the days:
DayHourCounts$Var1 = factor(DayHourCounts$Var1, ordered=TRUE,
                            levels=c("Monday", "Tuesday", "Wednesday",
                                     "Thursday", "Friday", "Saturday", "Sunday"))
#Change the label on the legend, and get rid of the y-label:
ggplot(DayHourCounts, aes(x = Hour, y = Var1)) + geom_tile(aes(fill = Freq)) +
  scale_fill_gradient(name="Total Tickets", low="white", high="red") +
  theme(axis.title.y = element_blank())
```

__Insights from the Visuals__

The EDA illustrates patterns between our variables and leads us to believe that we should be able to predict frequency of police ticketing by the hour of the day and day of the week.

\pagebreak

# Machine Learning Methods
Before I start the machine learning process I partition the data into a training and test set. Our models will learn from the training data set and then make predictions on the test set, data it has never seen. 

```{r, echo= FALSE}

DayHourCounts <- setNames(DayHourCounts, c("Weekday","Hour","Frequency",
                                           "HourAsNumber", "Weekday/Weekend"))
#
set.seed(21)
test_index <- createDataPartition(y = DayHourCounts$Frequency, times = 1,
                                  p = 0.2, list = FALSE)
my_train <- DayHourCounts[-test_index,]
test <- DayHourCounts[test_index,]
```

We are evaluating our models with the RMSE. Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). In other words, it tells us the difference between our predictions and our values we are predicting. The following is the RSME equation.  

   \[
    \makebox[\linewidth]{$RMSE = \sqrt{\frac{1}{n}\Sigma_{i=1}^{n}{\Big(\frac{d_i -f_i}{\sigma_i}\Big)^2}}$}
    \]
    
The following code generates a function that will calculate the RMSE for actual values (true_Frequency) from our test set to their corresponding predictors from our models:

    
```{r}
RMSE <- function(true_Frequency, predicted_Frequency){
  sqrt(mean((true_Frequency - predicted_Frequency)^2))
}
```

#Baseline Model

We will start with our baseline, the most basic prediction model. In statistics this would be $\hat{\mu}$ which is the average for all hours across all days of the week and use this average to predict our ticketing.

```{r, echo=FALSE}
mu_hat <- mean(my_train$Frequency)
mu_hat 
```

Now that we have our $\hat{\mu}$ we can determine RMSE for our baseline method. 

```{r, }
Baseline_rmse <- RMSE(test$Frequency, mu_hat)
Baseline_rmse 
```

We are getting a RMSE of about 656. Our prediction is on average 656 of citation off the actual amount of citations that are given for each day. This is the case for a couple of reasons, there seems to be days of very high amounts and then days that are very low tickets that are given. 

```{r, echo= FALSE}
rmse_results <- data_frame(method = "Baseline", RMSE = Baseline_rmse)
rmse_results %>% knitr::kable()
```

#Linear Regression

Linear Regression is a global model, where there is a single predictive formula that is used to determine an entire data-space. When the independent variables interact with each other in linear fashion this model works really well.

Now let’s run a linear regression model to see if we can improve on our baseline model


  \[
    \makebox[\linewidth]{${Y}_{}=a+b_1X_1+b_2X_2 +\varepsilon$}
    \]
    
$Y$ is your prediction, $a$ is the intercept, $b$ is the slope, $X$ is the observed score on the independent variable and $\varepsilon$ represents the residuals. 

```{r, echo= FALSE}
LR = lm(Frequency ~ Weekday + Hour, data=my_train) 

```

```{r, echo= FALSE}
LR_pred <- predict(LR, newdata=test)

LR_rmse <- RMSE(test$Frequency, LR_pred)
LR_rmse 
```

This is an improvement on our baseline model. This model appears to be learning and there is to at least some extent some linear correlation between the variables.

```{r, echo= FALSE}
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Linear Regression Model",  
                                     RMSE = LR_rmse ))
rmse_results %>% knitr::kable()
```

##Regression Tree

Let’s see if we can beat the Linear Regression Model with a Regression Tree Model.

Regression Trees use recursive partitioning to separate data in to smaller regions that are similar. This method works really well when the data interacts in complicated nonlinear ways. The tree will start with a root node often times have branches that partition the data will lead to the leaves or terminal nodes. 
<p>


```{r ,fig.align='center',out.width="350px", out.height="300px", echo=FALSE}
Tree = rpart(Frequency~ Weekday + Hour, data=my_train) 
prp(Tree)
```



```{r , echo=FALSE}
Tree_pred = predict(Tree, newdata=test)
Tree_rmse <- RMSE(test$Frequency, Tree_pred)
Tree_rmse 
```

Let's interpret this tree using the two examples from the beginning.

The first person's meter was about to expire at noon. Since, "12" is not listed in the root node, you would go to the first branch on the right. It was on Wednesday, which leads you to the far-right leaf or terminal node, 2970. This means at this time day on this day of the week, our model predicts that there are 2,970 tickets being issued. This is the peak ticketing time, and if this person wants to avoid a ticket they need to get to the meter and put in more money. 

The second person is considering illegally parking at 8am, which is also not in the root node. Again, we will progress to the right side of the tree. It is a Saturday; we would move left leaf from this branch. In this circumstance, there are only 258 tickets being issued at this time for this day of the week. According to our model the likelihood of receiving a ticket are the lowest among all the days and all the times of day, perhaps this would be the time to take the risk.

To take the risk or not, is not for me to decide, I am just putting forth additional information for that person to better understand the risks and help them make their decision.


#Cross Validation

When using machine learning, it is important to be mindful of overfitting or underfitting models. Cross validations allow for an opportunity to understand our tree better while finding out if our tree is the right size. 

We can evaluate our tree by plotting the cp. Our tree has 6 terminal nodes and has a cp of .011. The graph below shows us that the first split gives us the largest improvement and as we continue to split the smaller the improvement. 

```{r ,fig.align='center',out.width="350px", out.height="300px", echo=FALSE}
plotcp(Tree)
```

It appears that we have diminishing returns when we have 3 or 5 terminal nodes.  I am going to prune our tree to have 5 leaves and see how it predicts our test set. 
__Note:__ If there is a small difference in the RMSE, this would be a sign of overfitting and pruning would be necessary even though we would have a slightly larger RMSE.


```{r ,fig.align='center',out.width="350px", out.height="300px", echo=FALSE}
Tree1 <- rpart(Frequency~ Weekday + Hour, data=my_train, 
    control = list(cp = .021))
prp(Tree1)

Tree1_pred = predict(Tree1, newdata=test)
Tree1_rmse <- RMSE(test$Frequency, Tree1_pred)
Tree1_rmse 
    
```

There is a big difference in RMSE, indicating that our original tree is the proper size.
<p>

##Results
```{r, echo= FALSE}

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regression Tree Model",  
                                     RMSE = Tree_rmse ))
rmse_results %>% knitr::kable()
```

The results demonstrate that are models were in fact learning. The Linear Regression model was able to improve from our baseline, verifying there are some linear correlation between the independent variables and the dependent variable. Although our data has some linear correlations, ultimately our data prove to be more complicated and non-linear, this is the reason our tree model out performed our Linear Regression model. 


##Conclusion:

We have achieved our goal to effectively used machine learning methods to detect patterns of police ticketing in Los Angeles and successfully predicted the amount of tickets being issued on any given hour, on any given day of the week. We can be confident in our results because we can support our results with our exploratory data analysis. 

We also showed how machine learning can benefit everyday decisions. As explained in the Regression Tree section, the person at the building department has a high chance to receive a ticket and would be remiss if they did not go to the meter and add money. The second person was at a low risk of getting a ticket and may decide this amount of risk is worth taking.  


## Shiny application:

I created a interactive map with a shiny application. You can visit it at the URL below.

https://nathans.shinyapps.io/LA_Parking_Violations/
